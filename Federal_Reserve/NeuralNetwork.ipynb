{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Training_File_5_Day_Period.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start_Date</th>\n",
       "      <th>Start_Date_Close</th>\n",
       "      <th>End_Date</th>\n",
       "      <th>End_Date_Close</th>\n",
       "      <th>Difference</th>\n",
       "      <th>Difference_Percent_Change</th>\n",
       "      <th>Increase_Sum</th>\n",
       "      <th>Decrease_Sum</th>\n",
       "      <th>Dec_Inc_Ratio</th>\n",
       "      <th>Movement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1996-12-04</td>\n",
       "      <td>745.099976</td>\n",
       "      <td>1996-12-11</td>\n",
       "      <td>740.729980</td>\n",
       "      <td>-4.369996</td>\n",
       "      <td>-0.005865</td>\n",
       "      <td>272.73292</td>\n",
       "      <td>5540.78858</td>\n",
       "      <td>20.315804</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997-01-22</td>\n",
       "      <td>786.229980</td>\n",
       "      <td>1997-01-29</td>\n",
       "      <td>772.500000</td>\n",
       "      <td>-13.729980</td>\n",
       "      <td>-0.017463</td>\n",
       "      <td>481.87092</td>\n",
       "      <td>387.23080</td>\n",
       "      <td>0.803599</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997-03-12</td>\n",
       "      <td>804.260010</td>\n",
       "      <td>1997-03-19</td>\n",
       "      <td>785.770020</td>\n",
       "      <td>-18.489990</td>\n",
       "      <td>-0.022990</td>\n",
       "      <td>364.89519</td>\n",
       "      <td>4022.78681</td>\n",
       "      <td>11.024499</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997-05-07</td>\n",
       "      <td>815.619995</td>\n",
       "      <td>1997-05-14</td>\n",
       "      <td>836.039978</td>\n",
       "      <td>20.419983</td>\n",
       "      <td>0.025036</td>\n",
       "      <td>4296.04537</td>\n",
       "      <td>183.26339</td>\n",
       "      <td>0.042659</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997-06-18</td>\n",
       "      <td>889.059998</td>\n",
       "      <td>1997-06-25</td>\n",
       "      <td>888.989990</td>\n",
       "      <td>-0.070008</td>\n",
       "      <td>-0.000079</td>\n",
       "      <td>192.66714</td>\n",
       "      <td>7175.99356</td>\n",
       "      <td>37.245550</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Start_Date  Start_Date_Close    End_Date  End_Date_Close  Difference  \\\n",
       "0  1996-12-04        745.099976  1996-12-11      740.729980   -4.369996   \n",
       "1  1997-01-22        786.229980  1997-01-29      772.500000  -13.729980   \n",
       "2  1997-03-12        804.260010  1997-03-19      785.770020  -18.489990   \n",
       "3  1997-05-07        815.619995  1997-05-14      836.039978   20.419983   \n",
       "4  1997-06-18        889.059998  1997-06-25      888.989990   -0.070008   \n",
       "\n",
       "   Difference_Percent_Change  Increase_Sum  Decrease_Sum  Dec_Inc_Ratio  \\\n",
       "0                  -0.005865     272.73292    5540.78858      20.315804   \n",
       "1                  -0.017463     481.87092     387.23080       0.803599   \n",
       "2                  -0.022990     364.89519    4022.78681      11.024499   \n",
       "3                   0.025036    4296.04537     183.26339       0.042659   \n",
       "4                  -0.000079     192.66714    7175.99356      37.245550   \n",
       "\n",
       "   Movement  \n",
       "0        -1  \n",
       "1        -1  \n",
       "2        -1  \n",
       "3         1  \n",
       "4        -1  "
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data = data[['Increase_Sum', 'Decrease_Sum', 'Dec_Inc_Ratio']]\n",
    "X = feature_data.values[:,:]\n",
    "\n",
    "movement_data = data['Movement']\n",
    "Y = movement_data.values[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "288/288 [==============================] - 15s 51ms/step - loss: 1.0564 - acc: 0.5660\n",
      "Epoch 2/100\n",
      "288/288 [==============================] - 0s 406us/step - loss: 1.0563 - acc: 0.5694\n",
      "Epoch 3/100\n",
      "288/288 [==============================] - 0s 391us/step - loss: 1.0563 - acc: 0.5694\n",
      "Epoch 4/100\n",
      "288/288 [==============================] - 0s 443us/step - loss: 1.0562 - acc: 0.5694\n",
      "Epoch 5/100\n",
      "288/288 [==============================] - 0s 407us/step - loss: 1.0562 - acc: 0.5694\n",
      "Epoch 6/100\n",
      "288/288 [==============================] - 0s 393us/step - loss: 1.0561 - acc: 0.5694\n",
      "Epoch 7/100\n",
      "288/288 [==============================] - 0s 381us/step - loss: 1.0560 - acc: 0.5694\n",
      "Epoch 8/100\n",
      "288/288 [==============================] - 0s 347us/step - loss: 1.0559 - acc: 0.5694\n",
      "Epoch 9/100\n",
      "288/288 [==============================] - 0s 388us/step - loss: 1.0559 - acc: 0.5694\n",
      "Epoch 10/100\n",
      "288/288 [==============================] - 0s 349us/step - loss: 1.0558 - acc: 0.5694\n",
      "Epoch 11/100\n",
      "288/288 [==============================] - 0s 351us/step - loss: 1.0558 - acc: 0.5694\n",
      "Epoch 12/100\n",
      "288/288 [==============================] - 0s 384us/step - loss: 1.0558 - acc: 0.5694\n",
      "Epoch 13/100\n",
      "288/288 [==============================] - 0s 376us/step - loss: 1.0557 - acc: 0.5694\n",
      "Epoch 14/100\n",
      "288/288 [==============================] - 0s 344us/step - loss: 1.0557 - acc: 0.5694\n",
      "Epoch 15/100\n",
      "288/288 [==============================] - 0s 386us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 16/100\n",
      "288/288 [==============================] - 0s 358us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 17/100\n",
      "288/288 [==============================] - 0s 365us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 18/100\n",
      "288/288 [==============================] - 0s 370us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 19/100\n",
      "288/288 [==============================] - 0s 365us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 20/100\n",
      "288/288 [==============================] - 0s 390us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 21/100\n",
      "288/288 [==============================] - 0s 396us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 22/100\n",
      "288/288 [==============================] - 0s 453us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 23/100\n",
      "288/288 [==============================] - 0s 546us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 24/100\n",
      "288/288 [==============================] - 0s 394us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 25/100\n",
      "288/288 [==============================] - 0s 392us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 26/100\n",
      "288/288 [==============================] - 0s 368us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 27/100\n",
      "288/288 [==============================] - 0s 398us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 28/100\n",
      "288/288 [==============================] - 0s 491us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 29/100\n",
      "288/288 [==============================] - 0s 504us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 30/100\n",
      "288/288 [==============================] - 0s 431us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 31/100\n",
      "288/288 [==============================] - 0s 416us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 32/100\n",
      "288/288 [==============================] - 0s 407us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 33/100\n",
      "288/288 [==============================] - 0s 417us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 34/100\n",
      "288/288 [==============================] - 0s 449us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 35/100\n",
      "288/288 [==============================] - 0s 392us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 36/100\n",
      "288/288 [==============================] - 0s 419us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 37/100\n",
      "288/288 [==============================] - 0s 356us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 38/100\n",
      "288/288 [==============================] - 0s 395us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 39/100\n",
      "288/288 [==============================] - 0s 399us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 40/100\n",
      "288/288 [==============================] - 0s 351us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 41/100\n",
      "288/288 [==============================] - 0s 376us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 42/100\n",
      "288/288 [==============================] - 0s 364us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 43/100\n",
      "288/288 [==============================] - 0s 377us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 44/100\n",
      "288/288 [==============================] - 0s 373us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 45/100\n",
      "288/288 [==============================] - 0s 357us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 46/100\n",
      "288/288 [==============================] - 0s 373us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 47/100\n",
      "288/288 [==============================] - 0s 386us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 48/100\n",
      "288/288 [==============================] - 0s 422us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 49/100\n",
      "288/288 [==============================] - 0s 402us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 50/100\n",
      "288/288 [==============================] - 0s 413us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 51/100\n",
      "288/288 [==============================] - 0s 422us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 52/100\n",
      "288/288 [==============================] - 0s 624us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 53/100\n",
      "288/288 [==============================] - 0s 972us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 54/100\n",
      "288/288 [==============================] - 0s 934us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 55/100\n",
      "288/288 [==============================] - 0s 843us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 56/100\n",
      "288/288 [==============================] - 0s 526us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 57/100\n",
      "288/288 [==============================] - 0s 502us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 58/100\n",
      "288/288 [==============================] - 0s 457us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 59/100\n",
      "288/288 [==============================] - 0s 392us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 60/100\n",
      "288/288 [==============================] - 0s 418us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 61/100\n",
      "288/288 [==============================] - 0s 477us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 62/100\n",
      "288/288 [==============================] - 0s 504us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 63/100\n",
      "288/288 [==============================] - 0s 489us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 64/100\n",
      "288/288 [==============================] - 0s 560us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 65/100\n",
      "288/288 [==============================] - 0s 480us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 66/100\n",
      "288/288 [==============================] - 0s 486us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 67/100\n",
      "288/288 [==============================] - 0s 631us/step - loss: 1.0556 - acc: 0.5694 0s - loss: 1.1133 - acc: 0.554\n",
      "Epoch 68/100\n",
      "288/288 [==============================] - 0s 525us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 69/100\n",
      "288/288 [==============================] - 0s 1ms/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 70/100\n",
      "288/288 [==============================] - 0s 1ms/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 71/100\n",
      "288/288 [==============================] - 0s 465us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 72/100\n",
      "288/288 [==============================] - 0s 476us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 73/100\n",
      "288/288 [==============================] - 0s 447us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 74/100\n",
      "288/288 [==============================] - 0s 946us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 75/100\n",
      "288/288 [==============================] - 0s 830us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 76/100\n",
      "288/288 [==============================] - 0s 564us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 77/100\n",
      "288/288 [==============================] - 0s 565us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 78/100\n",
      "288/288 [==============================] - 0s 478us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 79/100\n",
      "288/288 [==============================] - 0s 766us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 80/100\n",
      "288/288 [==============================] - 0s 780us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 81/100\n",
      "288/288 [==============================] - 0s 539us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 82/100\n",
      "288/288 [==============================] - 0s 531us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288/288 [==============================] - 0s 1ms/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 84/100\n",
      "288/288 [==============================] - 0s 649us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 85/100\n",
      "288/288 [==============================] - 0s 516us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 86/100\n",
      "288/288 [==============================] - 0s 421us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 87/100\n",
      "288/288 [==============================] - 0s 486us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 88/100\n",
      "288/288 [==============================] - 0s 630us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 89/100\n",
      "288/288 [==============================] - 0s 383us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 90/100\n",
      "288/288 [==============================] - 0s 435us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 91/100\n",
      "288/288 [==============================] - 0s 444us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 92/100\n",
      "288/288 [==============================] - 0s 572us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 93/100\n",
      "288/288 [==============================] - 0s 929us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 94/100\n",
      "288/288 [==============================] - 0s 619us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 95/100\n",
      "288/288 [==============================] - 0s 893us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 96/100\n",
      "288/288 [==============================] - 0s 458us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 97/100\n",
      "288/288 [==============================] - 0s 607us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 98/100\n",
      "288/288 [==============================] - 0s 585us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 99/100\n",
      "288/288 [==============================] - 0s 522us/step - loss: 1.0556 - acc: 0.5694\n",
      "Epoch 100/100\n",
      "288/288 [==============================] - 0s 467us/step - loss: 1.0556 - acc: 0.5694\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17ff366d8>"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(3, input_dim=3, activation='relu'))\n",
    "model.add(Dense(9))\n",
    "model.add(Dense(91))\n",
    "model.add(Dense(25))\n",
    "model.add(Dense(12))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, epochs=100, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8219178318977356, 0.1780821979045868]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(X_test, Y_test, batch_size=128, verbose=2)\n",
    "loss_and_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.]], dtype=float32)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = np.array([[4775.277670000069, 462.0482700000007, 0.09675840902461993]])\n",
    "model.predict(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_851 (Dense)            (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dense_852 (Dense)            (None, 9)                 36        \n",
      "_________________________________________________________________\n",
      "dense_853 (Dense)            (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "dense_854 (Dense)            (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "dense_855 (Dense)            (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "dense_856 (Dense)            (None, 1)                 10        \n",
      "=================================================================\n",
      "Total params: 328\n",
      "Trainable params: 328\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.hdf5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
